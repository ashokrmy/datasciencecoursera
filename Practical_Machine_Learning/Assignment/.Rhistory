str(training)
str(testing)
as.numeric(training$kurtosis_roll_dumbbell)
as.character(training$kurtosis_roll_dumbbell)
as.numeric(as.character(training$kurtosis_roll_dumbbell))
as.numeric(as.character(training$kurtosis_roll_dumbbell))
?read.csv
training <- read.csv(training.file.name, header = TRUE, na.strings = "")
testing <- read.csv(testing.file.name, header = TRUE, na.strings = "")
str(training)
str(testing)
colClasses(training)
?apply
apply(training, 2, class)
apply(training, 2, class) == apply(testing, 2, class)
sum(apply(training, 2, class) == apply(testing, 2, class))
str(training)
# check that variables have the same class in both datasets
sum(apply(training, 2, class) == apply(testing, 2, class))
apply(training, 2, class) == apply(testing, 2, class)
training$classe
head(traiing)
head(training)
class(training$kurtosis_roll_belt)
training <- read.csv(training.file.name, header = TRUE, na.strings = "")
testing <- read.csv(testing.file.name, header = TRUE, na.strings = "")
str(training) # 160 variables, 19622 observations
training <- read.table(training.file.name, header = TRUE, sep =",",na.strings = "")
str(training) # 160 variables, 19622 observations
?read.csv
training <- read.csv(training.file.name, header = TRUE, stringsAsFactors = FALSE, na.strings = c("", "NA")
)
str(training) # 160 variables, 19622 observations
head(training)
training <- read.csv(training.file.name, header = TRUE, stringsAsFactors = FALSE)
testing <- read.csv(testing.file.name, header = TRUE, stringsAsFactors = FALSE)
# display structure of training and testing datasets
str(training) # 160 variables, 19622 observations
str(testing) # 160 variables, 20 observations
training$ $ var_accel_arm
training$var_accel_arm
str(training)
str(testing)
# check that variables have the same class in both datasets
apply(training, 2, class) == apply(testing, 2, class)
ncols(training)
nCols(training)
numCls(training)
numCols(training)
ncol(training)
(ncol(training)==ncol(training))
sum(apply(training, 2, class) == apply(testing, 2, class)) == ncol(training)
as.numeric(as.character(training$amplitude_roll_dumbbell))
apply(training, 2, is.na)
# check if the data contains missing values
sapply(training, function(x)any(is.na(x)))
# print number of missing values by column
sapply(training, function(x)sum(is.na(x)))
na.values.cols <- sapply(training, function(x)sum(is.na(x)))
table(na.values.cols)
19216 / 19622
str(training)
na.values.cols
na.values.cols > 0
na.values.cols [na.values.cols > 0]
names(na.values.cols [na.values.cols > 0])
na.values.cols.names <- names(na.values.cols [na.values.cols > 0])
training2 <- training[,-na.values.cols]
str(training2)
names(training)
training2 <- training[,!(names(training)%in%na.values.cols)]
str(training2)
training[,!(names(training)%in%na.values.cols)]
training2 <- sapply(training, function(x)as.numeric(as.character(x)))
str(training2)
head(training2)
names(training)[1:7]
(identifiers <- names(training)[1:7])
training2 <- training[,-identifiers]
training2 <- training[,!identifiers]
training2 <- training[,-"X"]
training2 <- training[,-X]
vars.identifiers <- names(training) %in% identifiers
training2 <- training[,-vars.identifiers]
str(training2)
(identifiers <- names(training)[1:7])
vars.identifiers <- names(training) %in% identifiers
identifiers
vars.identifiers
training2 <- training[,!vars.identifiers]
str(training)
str(training2)
training2 <- sapply(training2, function(x)as.numeric(as.character(x)))
str(training)
str(training2)
# print number of missing values by column
na.values.cols <- sapply(training2, function(x)sum(is.na(x)))
(identifiers <- names(training)[1:7])
vars.identifiers <- names(training) %in% identifiers
training2 <- training[,!vars.identifiers]
# print number of missing values by column
na.values.cols <- sapply(training2, function(x)sum(is.na(x)))
table(na.values.cols) # 67 variables have 19216 NA's
vars.nas <- names(training2) %in% na.values.cols.names
training2 <- training2[,!vars.nas]
str(training2)
na.values.cols.names <- names(na.values.cols [na.values.cols > 0])
na.values.cols.names
(identifiers <- names(training)[1:7])
vars.identifiers <- names(training) %in% identifiers
training2 <- training[,!vars.identifiers]
# print number of missing values by column
na.values.cols <- sapply(training2, function(x)sum(is.na(x)))
table(na.values.cols) # 67 variables have 19216 NA's
# get the name of the variables to exclude
na.values.cols.names <- names(na.values.cols [na.values.cols > 0])
vars.nas <- names(training2) %in% na.values.cols.names
training3 <- training2[,!vars.nas]
str(training3)
na.values.cols.names
training3$var_yaw_forearm
training2$var_yaw_forearm
apply(training2, 2,  function(x)as.numeric(as.character(x)))
training3 <- apply(training2, 2,  function(x)as.numeric(as.character(x)))
warnings()
testing2 <- testing[,!vars.identifiers]
training3$classe
str(training3)
training3 <- as.data.frame(apply(training2, 2,  function(x)as.numeric(as.character(x))))
str(training3)
training3$classe
training3$classe <- training$classe
str(training3)
training3$classe
na.values.cols <- sapply(training3, function(x)sum(is.na(x)))
table(na.values.cols) # 67 variables have 19216 NA's
sum(na.values.cols>0)
# get the name of the variables to exclude
na.values.cols.names <- names(na.values.cols [na.values.cols > 0])
vars.nas <- names(training3) %in% na.values.cols.names
training4 <- training3[,!vars.nas]
testing4 <- testing3[,!vars.nas]
testing3 <- as.data.frame(apply(testing2, 2,  function(x)as.numeric(as.character(x))))
testing3$classe <- testing$classe
# print number of missing values by column
na.values.cols <- sapply(training3, function(x)sum(is.na(x)))
table(na.values.cols)
sum(na.values.cols>0)# 100 variables have at least 19216 NA's
str(training4)
str(testing4)
testing4 <- testing3[,!vars.nas]
str(testing4)
unique(training4$problem_id)
training4 <- training3[,!vars.nas]
unique(training4$problem_id)
training4$problem_id
testing$problem_id
testing4$problem_id
testing4$classe
testing$classe
str(training$classe)
str(testing$classe)
str(testing)
str(training) # 160 variables, 19622 observations
str(testing) # 160 variables, 20 observations
# get the name of the identifiers
(identifiers <- names(training)[1:7])
vars.identifiers <- names(training) %in% identifiers
# exclude identifiers
training2 <- training[,!vars.identifiers]
testing2 <- testing[,!vars.identifiers]
# convert to character then to numeric
# char "" is converted to NAs
training3 <- as.data.frame(apply(training2, 2,  function(x)as.numeric(as.character(x))))
testing3 <- as.data.frame(apply(testing2, 2,  function(x)as.numeric(as.character(x))))
# bring back the classe variable
training3$classe <- training$classe
# number of missing values by column
na.values.cols <- sapply(training3, function(x)sum(is.na(x)))
table(na.values.cols)
sum(na.values.cols>0) # 100 variables have at least 19216 NA's
# number of missing values by column
na.values.cols <- sapply(training3, function(x)sum(is.na(x)))
table(na.values.cols) # 53 variables without missing values
sum(na.values.cols>0) # 100 variables have at least 19216 NA's
# get the name of the variables to exclude
na.values.cols.names <- names(na.values.cols [na.values.cols > 0])
vars.nas <- names(training3) %in% na.values.cols.names
# exclude NAs variables
training4 <- training3[,!vars.nas]
testing4 <- testing3[,!vars.nas]
str(training4)
str(testing4)
str(training4)
str(testing4)
pairs(training4)
?pair
?paris
?pairs
?pairs(classe~., data = training4)
pairs(classe~., data = training4)
sapply(trainin4,2,class)
apply(training4,2,class)
str(training4)
apply(training4,2,class)
head(training4)
training4$classe <- as.factor(training4$classe)
str(training4)
apply(training4,2,class)
class(training4)
class(training4$classe)
class(training4$magnet_forearm_z)
apply(training4,1,class)
sapply(training4,class)
sapply(training4,class) == sapply(testing4,class)
sapply(training4[,-53],class) == sapply(testing4[-53],class)
names(training4[,-53]) == names(testing4[-53])
type(training4)
pairs(classe~., data= training4[, c(1,2,53)])
pairs(classe~., data= training4)
pairs(classe~., data= training4)
library(corrgram)
install.packages("corrgram")
library(corrgram)
corrgram(training4[,-53], order=NULL, lower.panel=panel.shade,
upper.panel=NULL, text.panel=panel.txt,
main="Correlation between features")
corrgram(training4[sample(1000),-53], order=NULL, lower.panel=panel.shade,
upper.panel=NULL, text.panel=panel.txt,
main="Correlation between features")
cor(training4[,-53], use="complete.obs", method="pearson")
data=melt(cor(training4[sample(1000),-53]))
library(ggplot2)
library(reshape2)
install.packages("ggplot2")
install.packages("reshape2")
library(ggplot2)
library(reshape2)
data=melt(cor(training4[sample(1000),-53]))
str(data)
qplot(x=Var1, y=Var2, data=melt(cor(training4[sample(1000),-53])), fill=value, geom="tile")
qplot(x=Var1, y=Var2, data=melt(cor(training4[,-53])), fill=value, geom="tile")
qplot(x=Var1, y=Var2, data=melt(cor(training4[,-53])), fill=value, geom="tile") + theme(axis.text.x = element_text(angle = 90, hjust = 1))
data=melt(cor(training4[,-53]))
?corrgram
corrgram(cor(training4[,-53]), order=NULL, lower.panel=panel.shade,
upper.panel=NULL, text.panel=panel.txt,
main="Correlation between features")
qplot(x=Var1, y=Var2, data=melt(cor(training4[,-53])), geom="tile", scale_fill_gradient2(limits=c(-1, 1)) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
)
qplot(x=Var1, y=Var2, data=melt(cor(training4[,-53])), geom="tile", scale_fill_gradient2(limits=c(-1, 1))) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
data=melt(cor(training4[,-53]))
data
qplot(x=Var1, y=Var2, data=melt(cor(training4[,-53])), scale_fill_gradient2(limits=c(-1, 1))) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
qplot(x=Var1, y=Var2, data=melt(cor(training4[,-53],use="p")), scale_fill_gradient2(limits=c(-1, 1))) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
data <- airquality[,1:4]
library(ggplot2)
library(reshape2)
qplot(x=Var1, y=Var2, data=melt(cor(data, use="p")), fill=value, geom="tile") +
scale_fill_gradient2(limits=c(-1, 1))
qplot(x=Var1, y=Var2, data=melt(cor(training4[,-53], use="p")), fill=value, geom="tile") +
scale_fill_gradient2(limits=c(-1, 1)) +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
library(caret)
install.packages("caret")
findCorrelation(training4[,-53], cutoff = .90, verbose = FALSE)
library(caret)
findCorrelation(training4[,-53], cutoff = .90, verbose = FALSE)
?findCorrelation
findCorrelation(cor(training4[,-53]), cutoff = .90, verbose = FALSE)
findCorrelation(cor(training4[,-53]), cutoff = .90, verbose = TRUE)
findCorrelation(cor(training4[,-53]), cutoff = .90, verbose = FALSE)
cor(training4[,-53], use="p")
?cor
qplot(x=Var1, y=Var2, data=melt(cor(training4[,-53])), fill=value, geom="tile") +
scale_fill_gradient2(limits=c(-1, 1)) +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
corr.matrix <- cor(training4[,-53])
# correlation matrix between features
corr.matrix <- cor(training4[,-53])
library(ggplot2)
library(reshape2)
qplot(x=Var1, y=Var2, data=melt(corr.matrix), fill=value, geom="tile") +
scale_fill_gradient2(limits=c(-1, 1)) +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
?corr
?cor
corr.matrix
corr.matrix["gyros_forearm_z", ]
corr.matrix[corr.matrix>90]
corr.matrix[corr.matrix>90,]
corr.matrix>0.9
corr.matrix[corr.matrix>0.9,]
corr.matrix[corr.matrix>0.9]
subset(corr.matrix, corr.matrix>0.9)
?cor
corr.matrix["gyros_forearm_z", ]
corr.matrix["gyros_forearm_z", ]>0.9
corr.matrix[corr.matrix["gyros_forearm_z", ]>0.8,]
corr.matrix["gyros_forearm_z", ]>0.8
corr.matrix["gyros_forearm_z", ]>0.8==TRUE
corr.matrix["gyros_forearm_z", ]>0.8=TRUE
?subset
subset(corr.matrix["gyros_forearm_z", ]>0.8, TRUE)
class(corr.matrix["gyros_forearm_z", ]>0.8)
str(corr.matrix["gyros_forearm_z", ]>0.8)
subset(corr.matrix["gyros_forearm_z", ]>0.8, corr.matrix["gyros_forearm_z", ]>0.8 ==TRUE)
subset(corr.matrix["gyros_forearm_z", ]>0.8, (corr.matrix["gyros_forearm_z", ]>0.8) == TRUE)
subset(corr.matrix["gyros_forearm_z", ], (corr.matrix["gyros_forearm_z", ]>0.8) == TRUE)
subset(corr.matrix["gyros_forearm_z", ], (corr.matrix["gyros_forearm_z", ]>0.9) == TRUE)
subset(corr.matrix, corr.matrix > 0.8)
corr.matrix > 0.8
subset(corr.matrix, (corr.matrix > 0.8) ==TRUE)
findCorrelation(corr.matrix, cutoff = .90, verbose = FALSE)
library(caret)
findCorrelation(corr.matrix, cutoff = .90, verbose = FALSE)
corr.matrix[10]
names(corr.matrix)
rownames(corr.matrix)
rownames(corr.matrix)[10]
colnames(corr.matrix)[10]
subset(corr.matrix["accel_belt_z", ], (corr.matrix["accel_belt_z", ]>0.8) == TRUE)
findCorrelation(corr.matrix, cutoff = .90, verbose = FALSE)
?findCorrelation
high.cor.var <- findCorrelation(corr.matrix, cutoff = -.90, verbose = FALSE)
high.cor.var
corr.matrix["accel_belt_z", ]
high.cor.var <- findCorrelation(corr.matrix, cutoff = .80, verbose = FALSE)
high.cor.var
?findCorrelations
?findCorrelation
high.cor.var <- findCorrelation(corr.matrix, cutoff = .80, verbose = FALSE)
high.cor.var.names <- rownames(cor.matrix)[high.cor.var]
high.cor.var.names <- rownames(corr.matrix)[high.cor.var]
(high.cor.var.names <- rownames(corr.matrix)[high.cor.var])
subset(corr.matrix["accel_belt_z", ], (abs(corr.matrix["accel_belt_z", ])>0.8) == TRUE)
subset(corr.matrix["gyros_forearm_z", ], (abs(corr.matrix["gyros_forearm_z", ])>0.8) == TRUE)
inTrain <- createDataPartition(training4$classe, p = 0.7, list = FALSE)
train.set <- training4[ inTrain,]
validation.set <- training4[-inTrain,]
set.seed(12345)
model1 <- train(classe~., data = train.set, method = 'rpart')
install.packages("e1071")
install.packages("rattle")
print(model1)
model1 <- train(classe~., data = train.set, method = 'rpart')
print(model1)
set.seed(12345)
model2 <- train(classe~., data = train.set[,-high.cor.var], method = 'rpart')
print(model2)
fancyRpartPlot(model2$finalModel)
library(rattle)
fancyRpartPlot(model2$finalModel)
library(rpart)
fancyRpartPlot(model2$finalModel)
library(rpart)
library(rattle)
fancyRpartPlot(model2$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(model2$finalModel)
library(rattle)
library(rpart)
fancyRpartPlot(model1$finalModel)
print(model1)
predict.model2 <- predict(model2, validation.set)
confusionMatrix(predict.model2, validation.set$classe)
predict.model1 <- predict(model1, validation.set)
confusionMatrix(predict.model1, validation.set$classe)
confusionMatrix(predict.model2, validation.set$classe)
set.seed(12345)
model3 <- train(classe~., data = train.set, method = 'rf')
model3 <- train(classe~., data = train.set[sample(1000),], method = 'rf')
print(model3)
warnings()
train.set[sample(1000),]
train.set[sample(1000),]$classe
confusionMatrix(predict.model2, validation.set$classe)
model3 <- train(classe~., data = train.set, method = 'rf')
?randomForest
set.seed(12345)
model3 <- train(classe~., data = train.set, method = 'rf',
trControl = trainControl(allowParallel=T,method = "cv",number = 10))
# read training and testing datasets
training <- read.csv(training.file.name, header = TRUE, stringsAsFactors = FALSE)
testing <- read.csv(testing.file.name, header = TRUE, stringsAsFactors = FALSE)
# display structure of training and testing datasets
str(training) # 160 variables, 19622 observations
str(testing) # 160 variables, 20 observations
# get the name of the identifiers
(identifiers <- names(training)[1:7])
vars.identifiers <- names(training) %in% identifiers
# exclude identifiers
training2 <- training[,!vars.identifiers]
testing2 <- testing[,!vars.identifiers]
# convert to character then to numeric
# char "" is converted to NAs
training3 <- as.data.frame(apply(training2, 2,  function(x)as.numeric(as.character(x))))
testing3 <- as.data.frame(apply(testing2, 2,  function(x)as.numeric(as.character(x))))
# bring back the classe variable
training3$classe <- training$classe
# dataset folder to store the training and testing dataset
data.folder <- "./Datasets/"
# current date in format YYYYMMDD
date <- gsub(pattern="-", replacement = "", Sys.Date())
training.file.name <- paste(data.folder,"training_",date,".csv", sep="")
testing.file.name <- paste(data.folder,"testing_",date,".csv", sep="")
training <- read.csv(training.file.name, header = TRUE, stringsAsFactors = FALSE)
testing <- read.csv(testing.file.name, header = TRUE, stringsAsFactors = FALSE)
# display structure of training and testing datasets
str(training) # 160 variables, 19622 observations
str(testing) # 160 variables, 20 observations
# get the name of the identifiers
(identifiers <- names(training)[1:7])
vars.identifiers <- names(training) %in% identifiers
# exclude identifiers
training2 <- training[,!vars.identifiers]
testing2 <- testing[,!vars.identifiers]
training3 <- as.data.frame(apply(training2, 2,  function(x)as.numeric(as.character(x))))
testing3 <- as.data.frame(apply(testing2, 2,  function(x)as.numeric(as.character(x))))
# bring back the classe variable
training3$classe <- training$classe
na.values.cols <- sapply(training3, function(x)sum(is.na(x)))
table(na.values.cols) # 53 variables without missing values
sum(na.values.cols>0) # 100 variables have at least 19216 NA's
# get the name of the variables to exclude
na.values.cols.names <- names(na.values.cols [na.values.cols > 0])
vars.nas <- names(training3) %in% na.values.cols.names
# exclude NAs variables
training4 <- training3[,!vars.nas]
testing4 <- testing3[,!vars.nas]
training4$classe <- as.factor(training4$classe)
# check training and testing have same variables
names(training4[,-53]) == names(testing4[-53])
# check training and testing variables have the same type
sapply(training4[,-53],class) == sapply(testing4[-53],class)
# correlation matrix between features
corr.matrix <- cor(training4[,-53])
# plot heatmap of correlation
library(ggplot2)
library(reshape2)
qplot(x=Var1, y=Var2, data=melt(corr.matrix), fill=value, geom="tile") +
scale_fill_gradient2(limits=c(-1, 1)) +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
library(caret)
high.cor.var <- findCorrelation(corr.matrix, cutoff = .80, verbose = FALSE)
# highly correlated variables
(high.cor.var.names <- rownames(corr.matrix)[high.cor.var])
?sample
inTrain <- createDataPartition(training4$classe, p = 0.6, list = FALSE)
train.set <- training4[ inTrain,]
validation.set <- training4[-inTrain,]
length(train.set)
nrow(train.set)
model3 <- train(classe~., data = train.set[sample(nrow(train.set), 1000),-high.cor.var], method = 'rf',
trControl = trainControl(allowParallel=T,method = "cv",number = 10))
model3 <- train(classe~., data = train.set[sample(nrow(train.set), 1000),-high.cor.var], method = 'rf',
trControl = trainControl(method = "cv",number = 10))
?randomForest
model3 <- randomForest(classe~., data=train.set[sample(nrow(train.set), 1000),-high.cor.var], ntree=100)
print(model3)
model3 <- randomForest(classe~., data=train.set[,-high.cor.var], ntree=100)
print(model3)
str(train.set)
predict.model3 <- predict(model3, validation.set)
confusionMatrix(predict.model3, validation.set$classe)
?train
model3 <- train(classe~., data = train.set, method = 'rf')
model4 <- randomForest(classe~., data=train.set, ntree=100)
# check model 3 on validation set
predict.model3 <- predict(model4, validation.set)
confusionMatrix(predict.model4, validation.set$classe)
predict.model4 <- predict(model4, validation.set)
confusionMatrix(predict.model4, validation.set$classe)
# check model 3 on validation set
predict.model3 <- predict(model3, validation.set)
confusionMatrix(predict.model3, validation.set$classe)
confusionMatrix(predict.model4, validation.set$classe)
model3 <- randomForest(classe~., data=train.set[,-high.cor.var])
# check model 3 on validation set
predict.model3 <- predict(model3, validation.set)
confusionMatrix(predict.model3, validation.set$classe)
model.rpart <- rpart(classe~., data = train.set[,-high.cor.var])
# check model 1 on validation set
predict.model.rpart <- predict(model.rpart, validation.set)
confusionMatrix(predict.model.rpart, validation.set$classe)
predict.model.rpart <- predict(model.rpart, validation.set)
confusionMatrix(predict.model.rpart, validation.set$classe)
# randomly select 70% for training and 30% for validation
inTrain <- createDataPartition(training4$classe, p = 0.7, list = FALSE)
train.set <- training4[ inTrain,]
validation.set <- training4[-inTrain,]
# set seed for reproducibility
set.seed(12345)
model.rpart <- rpart(classe~., data = train.set[,-high.cor.var])
predict.model.rpart <- predict(model.rpart, validation.set)
confusionMatrix(predict.model.rpart, validation.set$classe)
predict.model.rpart
?predict.rpart
predict.model.rpart <- predict(model.rpart, validation.set, type="class")
confusionMatrix(predict.model.rpart, validation.set$classe)
set.seed(12345)
# randomly select 60% for training and 40% for validation
inTrain <- createDataPartition(training4$classe, p = 0.6, list = FALSE)
train.set <- training4[ inTrain,]
validation.set <- training4[-inTrain,]
set.seed(12345)
model.rpart <- rpart(classe~., data = train.set[,-high.cor.var])
predict.model.rpart <- predict(model.rpart, validation.set, type="class")
confusionMatrix(predict.model.rpart, validation.set$classe)
fancyRpartPlot(model.rpart)
?rpart
save.image("~/Dropbox/Data Science Specialization/8 - Practical Machine Learning/Assignment/workspace.RData")
